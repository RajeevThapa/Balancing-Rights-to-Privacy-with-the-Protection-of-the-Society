\chapter{Literature Review} \label{cha:Literature Review}
\section{Introduction to Cybersecurity and Privacy in a Digitalized Society}
The rapid advancement of digital technologies has transformed how societies operate, communicate, and govern information. As a result, cybersecurity which is the discipline of protecting systems, networks and programmes from digital attacks by preserving the CIA of computational resources has become the most important international issue \cite{salman2023evolution}.  The term's scope has broadened significantly beyond traditional information security, with the prefix "cyber" expanding its coverage to include critical infrastructure and industrial contexts, such as IoT systems\cite{sharma2023privacy}. Cybersecurity is directly linked to societal security because attacks represent a real danger that can affect the economy, national security, and personal privacy. In an environment where a significant amount of interactions are conducted online, the use of strict security standards implies the integration of basic data protection and privacy principles \cite{admass2024cyber}.\\

\noindent The shift to digitalized processes has resulted in a dramatic shift of the threat landscape with cyber attacks escalating from relatively simple attacks to complex and organized ones. The current environment is one of "smart and sophisticated attacks" utilizing highly advanced techniques. The new threats are complex malware, sophisticated, targeted and organized APTs and zero-day attacks that exploit previously unknown vulnerabilities  \cite{admass2024cyber}. In addition, due to digital transformation there have also come about new forms of threat, in particular the AI-driven attacks, in which attackers use AI and Machine Learning (ML) to improve their operations, the planning of attacks or even autonomously execute attacks. Furthermore, this increasing complexity, combined with a huge expansion in the number of connected devices, especially in the IoT ecosystem which often have weak security measures, gives rise to significant challenges. There are multiple information security strategies that organizations need to employ so that they can maintain continuous operations and also secure their Intellectual Capital  \cite{salman2023evolution}. 

\noindent The intricate interplay between digital trust and privacy is at the heart of ensuring the stability of a digitalized society. Cybersecurity is a key element in maintaining privacy and continuity of business and services and protecting both personal information (important for avoiding identity attacks) and business sensitive information. The amount of sensitive data that is being transmitted by IoT devices continues to increase, and as such, privacy protection has become an important factor, with poor data storage or encryption potentially resulting in a breach. In light of these global challenges, international and regional organizations have put in place strict mechanisms. 

\section{Types of Cybersecurity Threats Challenging Privacy and Data Protection}
As the world is becoming more and more digital, the issue of cybersecurity and privacy has become one of the most pressing concerns around the world, as networks and services provide an array of possibilities to malicious individuals to breach connections, disrupt services, steal information, and reveal sensitive data. The privacy and data protection rights of people are threatened by a variety of threats, including malicious software and social engineering, as well as highly advanced inference attacks, especially in sensitive areas such as health and genetic information. 
\noindent WannaCry is one of the most notorious ransomware attacks that happened in May 2017. The spread of WannaCry became widespread all over the world, with hundreds of thousands of computers already infected in more than 150 countries in several days \cite{askarifar2018review}. It took advantage of a vulnerability affecting Microsoft Windows called EternalBlue which had previously been created as a hacking tool by the American National Security Agency (NSA) and was eventually sold online to a hacker organization called the Shadow Brokers.\\

\noindent Once a system was infected, WannaCry encrypted files and displayed a red warning screen demanding a ransom of about \$300 to \$600 in Bitcoin. Large institutions like hospitals, banks and government agencies were also hit. For example, the UK’s National Health Service (NHS) suffered severe disruptions, leading to canceled appointments and delays in patient care \cite{collier2017nhs}. Microsoft subsequently issued emergency security patches in response to the vulnerability that was exploited, and computer security researchers were able to find a so-called kill switch that was used to stop the spread of the attack.\\

\noindent Keyloggers refer to the software programs that covertly observe the keyboard actions of the user in order to obtain and intercept important data such as bank details and passwords. Phishing and email spamming are other frequent types of network abuse and involve unwelcome online communication through the use of deception to steal clients' credentials. Social Engineering (SE) is a strategy where adversaries trick victims into revealing crucial information by gaining their trust, exploiting the human side of breaking into a corporate network. In addition, network attacks like Denial of Service (DoS) and Distributed Denial of Service (DDoS) attacks affect service resource overloading denying authorization \cite{safitra2023counterattacking}.APTs, or highly advanced attacks, are typically state or nation-created attacks to steal sensitive information. Data loss, identity theft, financial losses, and reputational damage are some of the perils that threats tend to bring. Prevention of these is by ensuring that the behavior of users, system logs and activities on the network are continuously monitored, which is associated with surveillance in threat detection.

\subsection* {Emerging Attack Vectors: Data Inference and Deanonymization}
\noindent New attack vectors target metadata, model updates, and cross organizational interactions rather than only exploiting software vulnerabilities. One growing issue in the privacy world  involves the disclosure of privacy-sensitive data generated by modern digital services. Large Language models collect interaction-level data for recommendation algorithms, fraud detection, and behavioral analysis. Even after identifiers are deleted, models can predict health status, financial stress, or behavioral traits using seemingly benign logs. These findings show that privacy loss can occur during the routine operation of digital platforms \cite{10731739}
For example, ChatGPT's training technique involves systematically scraping data from various places, including websites, posts, books, and articles that may contain personal information. The training dataset has increased to 570 GB, requiring significant real-world data, raising privacy concerns. Individual comments, blog posts, or product evaluations may have been utilized without the data owners' consent, perhaps in violation of privacy rules such as GDPR and CCPA \cite{WU2024102}. The possibility of the attackers to infer sensitive information or identity based on the information that has been secured is another possible area of future attack on the data protection area that is a significant emerging threat. Even though the conventional methods of anonymization can be used to both ban identity and attribute disclosure (that of an individual in a record as well as sensitivity attribute in a record), a more basic concern is the membership disclosure, i.e. whether an individual target is present in the dataset itself. Membership knowledge is said to be a prerequisite of identity and attribute disclosure.\\

\noindent To quantify this loss of privacy that has remained, one uses the new types of AI-based inference attacks. The new framework, which is grounded on the Shadow Model approach to approximate residual risks of membership inference on structured, tabular health data \cite{meurers2025phantom}. The attack is premised on training a classifier (e.g. a Random Forest) to determine the presence of a particular target record in an anonymized dataset. Experiments have shown that the signals that are detectable were always created by outlier targets that by nature possess more distinct and recognizable profiles. The most important is the fact that the sources can be successfully used to prove that the membership inference interference can be adequately defended by both the privacy model (e.g. by the k-Anonymity) and the method of transformation used to modify the data (e.g. by the generalization or microaggregation). Even though it is not directly stated as a technique applied in the new source, the overall aim of such inference attacks is deanonymization, which is attempting to match anonymized information to an individual.\\

\subsection* {Sector-Specific Threats}
As cyber threats continue to evolve, attackers are increasingly targeting specific industries that handle highly sensitive data or rely on critical systems, giving rise to sector-specific threats.   These include membership attacks, which can reveal whether an individual’s data is part of a dataset; genetic information and health data breaches, which threaten personal and medical privacy; and vulnerabilities in IoT and embedded systems, which can disrupt essential devices and infrastructure. These attacks unlike other types of general threats like malware or phishing take advantage of the vulnerabilities in their particular fields and their impact is more devastating and extensive. Being aware of these industry-specific threats is a crucial way to institute specific security strategies to safeguard individuals and organizations against highly specialized cyber threats.

\subsubsection* {Membership Attacks}
A membership attack (or membership inference attack) is a privacy breach where an adversary uses access to a model, database, or query interface to determine whether a specific individual’s data was included in the training set or underlying dataset. In genomics, this can reveal whether someone participated in a genetic study or appears in a DTC (direct-to-consumer) database, potentially exposing sensitive health or ancestry information. Attackers exploit differences in model behavior or query responses (e.g., confidence scores, likelihoods, or similarity measures) between records that were seen during training and those that were not techniques include shadow-models, likelihood-ratio tests, and similarity-based probing and can succeed even when direct identifiers are absent. The consequences are severe to genetic privacy since membership verification can be used to identify again, discriminate,  or unwanted contact, especially given DNA overlap \cite{nemecek2025exploring}. Some of the defenses used are restriction and auditing of query access, deletion or non-disclosure of confidence information, performing differential privacy and strong regularization with model training, aggregation or de-identification of outputs, and stringent access control and legal safeguards to make successful membership inference less likely.

\subsubsection* {Genetic Information Privacy}
Genetic information privacy refers to the protection of an individual’s unique genetic data, which contains highly personal information about ancestry, biological traits, and potential health risks. With the rise of DTC genetic testing services such as 23andMe and AncestryDNA, people can now easily upload their DNA data to explore family connections and health insights \cite{lee2025public}. Nevertheless, these services have placed genetic privacy in a very vulnerable position as they allow these users to place their genetic data online so that the user can search and find their relatives through identical by state (IBS) regions- a shared fragment of DNA that helps establish the genetic connections between users. This may assist in identifying the relatives, but it also discloses sensitive information that may be abused by hackers, insurance companies or the law enforcement without permission. Genetic data is permanent and uniquely identifying, therefore, when exposed to the world, there are long-term effects that may occur, including genetic discrimination or medical confidentiality loss. Hence, ensuring robust data security, open consent, and secure digital storage is the key measure to guarantee genetic privacy in the digital era. Adversaries can use the algorithms capable of identifying shared segments of genetic material to retrieve a large portion of raw genetic data of a user \cite{edge2020attacks}. These genetic privacy concerns extend not only to the person whose data is revealed but also to their relatives.
Distinct and new attack vectors against genetic data are:
\begin{itemize}
    \item IBS Tiling: In this protocol, an adversary publishes a large number of actual genotype (which may include publicly available genotype collections, such as the 1000Genomes Project) and combines the similar IBS segments with a target user \cite{edge2020attacks}. Through repeated comparison of small amounts of the target genotypes, the adversary is potentially able to eventually reveal a large portion of the target user genome. Edge et. al pointed that even with a median individual of European ancestries, uploading about 900 genomes would be able to reconstruct at least one allele in SNP sites in up to 82 percent of the genome.
   \item IBS Probing: It is done to determine people possessing a particular genotype of interest, e.g., risk alleles of an Alzheimer disease (e.g., in the APOE locus). The opponent exonerates a real haplotype fragment bearing the allele and inserts it into a fake genetic data set bordered by two artificial pieces of DNA named IBS-inert - artificial data set that is unlikely to match IBS regions with anybody in the database \cite{edge2020attacks}. Matches obtained in any resulting matches imply that the allele of interest is present in the users.
    \item IBS Baiting: This attack targets services that operate with phase-unaware IBS calling algorithms (that seeks out long areas without sites that are incompatible with the homozygous site). An opponent constructs unnatural datasets of long sequences of heterozygosity (which are not naturally distributed). The adversary can identify the genotype at only one site of interest of a user using only two uploads by homozygously inserting genotypes at important sites. An example of parallel IBS baiting, when short fragments (e.g., 1 cM) are reported, would reveal hundreds or thousands of sites resulting in an estimated 100 uploaded datasets being enough to enable any user in the database to inaccurately impute their genome (97 percent to 98 percent accuracy). It was demonstrated that GEDmatch was susceptible to IBS baiting  \cite{edge2020attacks}.
\end{itemize}
Moreover, certain services reinforce privacy threats by offering high-resolution pictures of comparisons of chromosomes at SNP-level resolutions, which allow reconstructing the entire genotype of a target.

\subsubsection* {Health Data and IoT/Embedded Systems}
Health data is one of the most sensitive and valuable types of personal information because it is directly related to the identity of an individual, his or her medical conditions, as well as overall well-being. The misuse of such data may be disastrous and result in factors such as discrimination, identity theft, reputational damage and distress. Health data frequently includes data on particular diseases, therapies, or genetic susceptibility of people \cite{meurers2025phantom}. In turn, despite the anonymization of data, membership inference attacks, during which an adversary makes conclusions about including the data of a specific person in a dataset, are still high. The nature of the problem is such a weakness since it is not always an easy task to reconcile privacy and data utility in healthcare analytics. Good anonymization can effectively reduce the utility of data in research and in machine learning applications, with high utility causing individuals to be vulnerable to re-identification. Therefore, privacy-sensitive methods, including differential privacy, homomorphic encryption, federated learning, and others, are currently being researched to ensure that sensitive health data are not violated, and their analysis is still valuable.\\

\noindent In parallel to this, the spread of Internet of Things (IoT) and embedded systems has added new spheres of cybersecurity risks. The IoT devices, including wearable health sensors and smart home appliances, as well as industrial sensors, are continuously creating and exchanging data on networks of networks \cite{meurers2025phantom}. Such devices are usually incapable of performing enough computation and lack sufficient security measures, which are prone to being exploited. Weak authentication, outdated firmware, or unencrypted communications can also be used by attackers to obtain an unauthorized access, alter device behavior, or steal data. Such vulnerabilities may affect the personal privacy, safety, and even physical security in smart home environments.\\

\noindent In addition, the integration of IoT and CPSS in fields such as healthcare, manufacturing and energy has enhanced the critical effect of cyberattacks. The compromise of such systems may affect the critical operations, causing major economic and social outcomes. Thus, companies should come up with well-built resilience frameworks to curb such risks. This includes assessing the vulnerability and reliability of both software and physical components, and has continuous monitoring and patch management, and architecture that is flexible and has the ability to recover in case of failure. Finally, Meurers et. al pointed the measures to improve the security posture of health data and IoT ecosystems cannot be achieved through unicast technological, organizational, and regulatory protection strategies\cite{meurers2025phantom}.
\\

According to the literature reviewed, inference, profiling, and extensive monitoring increasingly threaten privacy alongside direct cyberattacks. Research shows that even without direct data breaches, metadata, model outputs, and behavioral traces can disclose personal information. Specific research areas such as IoT, genetics, and health demonstrate that sensitive data environments amplify privacy risks and require continuous surveillance. Although, these studies identify significant threat patterns, they often treat technical risks and legal obligations as separate entities, leading to a lack of understanding of how cybersecurity threats translate into actual privacy infringements and legal challenges. A systematic approach to analyzing these threats based on their effects on privacy is necessary to address this gap which we will explore more in chapter 4.

\section{Legislative and Regulatory Frameworks: Balancing Privacy and Security}
Cybersecurity and data protection have become key priorities within the European Union due to the increasing number of cyber threats, data breaches, and the rapid digitalization of society and industry. In response, the EU has built a comprehensive regulatory framework, most notably the General Data Protection Regulation and the Networking and Information Systems Directive.\cite{berzins2025cybersecurity}. \\

\noindent In 2018, the GDPR was introduced that created a high-quality framework of data protection in all EU member states and is considered a worldwide standard. GDPR is particularly concerned with the personal information of individuals and strictly regulated all the organizations that process the data of EU citizens. Core principles of data processing are lawfulness, fairness and transparency; limitation of purpose (data should be collected to address certain, legitimate purposes); minimum data, accuracy, limitation of storage (later retention of data should not exceed the necessity), and integrity, and confidentiality \cite{berzins2025cybersecurity}. GDPR also grants fundamental data subject rights, which should be handled and enforced by data processors so that people could exercise freedom over what data about them is disclosed and the purposes of their use. The rights include right of access (transparency, Article 15), and the right to intervene (the right to erasure and the right to rectification), and the right to address data protection authorities. According to Kyriakoulis et. al. GDPR provides high standards of compliance requiring organizations are required to employ DPOs, conduct DPIA and provide breach reporting within 72 hours \cite{kyriakoulis2025consentis}. In addition, GDPR  requires data controllers and processors to implement appropriate technical and organizational security measures, including the use of PETs.\\

\noindent The EU first law on cybersecurity was the NIS Directive that was meant to enhance security of of essential services and digital service providers across the Union. However,The NIS1 Directive failed to establish uniform cybersecurity throughout the EU due to inconsistent implementation and inadequate standardization among member states. This difference resulted in inconsistencies in enforcement and supervision, as well as ineffective incident reporting. Furthermore, NIS1 failed to address intersectoral interdependencies, supply chain vulnerabilities,and the growing size of cyber attacks which reducing its effectiveness \cite{aunon2024evaluation}. In the revised law, the NIS2 Directive (Directive (EU) 2022/2555), this was broadened considerably and took effect in December 2022 \cite{10569809}. NIS2 will enhance the functionality of the internal market by establishing a high and uniform cybersecurity standard across the Union. Member states are required to develop country-level cybersecurity plans, creation of effective cybersecurity agencies, and CSIRTs. The Directive also contains the guidelines on how the big cyber event and crisis should be managed, including filing the national response plans with the EU Network of Cyber Crisis Liaison Organizations (EU-CyCLONe). NIS2 has a critical governance requirement that the governance bodies of both critical as well as significant entities ratify the cybersecurity risk management activities of the critical and significant entities, in line with the strategies discussed in the Directive. NIS2 provides the compliance with administrative punishment as well, fines against critical entities may require minimum fines up to 10,000,000 EUR or 2 percent of the annual global turnover, which is higher. Although GDPR concentrates on the protection of personal data while NIS2 focuses on the cybersecurity of critical infrastructure.  The two models of complement each other, as hacking often involves violations of personal data protection which requires a combined approach.\\

\noindent However, the steps of enforcing and aligning these legal systems are problematic in a number of ways. This complexity can negatively impact the establishment of network structures and may lead to a reduction, rather than an increase, in the level of cybersecurity and connectivity within the EU \cite{10569809}. The need for compliance often leads to compliance burdens, particularly for small and medium enterprises (SMEs), where resources are diverted to administrative tasks instead of improving actual security procedures. Berzins et. al pointed that the problem of ensuring a similar level of protection throughout the EU is further exacerbated by the differences in implementation due to legal and technological environment existing in the individual member states, and also the EU limits cross-border data transfers which is problematic to multinational companies \cite{berzins2025cybersecurity}. As a result, translating GDPR and NIS2 requirements into technical measures requires embedding data protection and security controls directly into system design and operation 

\section{Technical and Ethical Solutions for Responsible Data Processing}
EU data policies are increasingly emphasizing data sharing through regulated data spaces that combine technical infrastructures with regulatory procedures to support a single data market.. The Data Act regulates access to non-personal data to ensure fair data sharing among various actors in the data economy. The Data Governance Act, manages data intermediaries and strengthen trust among stakeholders. In addition, the High Value Datasets Implementing Act makes it easier to access certain datasets stored by governmental bodies. However, due to GDPR and ethical considerations, not all data can be shared openly, therefore, privacy preservation is an essential requirement for data spaces. \cite{mwiinga2023privacy}.

\subsection* {Privacy-Enhancing Technologies (PETs)}
PETs can be explained as a consistent set of Information and Communications Technology (ICT) control that has been established to ensure privacy, meaning to remove personal information or unnecessary processing, all while maintaining the functionality of the data system \cite{mwiinga2023privacy}. The technologies are set to derive value out of information without reducing the privacy of the user. Encryption is an underpinning pillar of privacy safeguarding that protects data by converting it to an unreadable form without the decryption key of the data, and as such means confidentiality even in case of unauthorized access. Encryption schemes include symmetric and asymmetric encryption methodologies, which are useful in ensuring the transmission and storage of data are secure.\\
One of the process anonymization methods, consist of the removal or modification of identifiable elements of datasets to protect individual identities and allow fair analysis to take place. Particular forms of anonymization, including k-anonymity and l-diversity are common in data publishing and data sharing environments. Nonetheless, the conventional ways of anonymity can be vulnerable to profiling attacks.
Conversely, DP adds noise or randomness to query answers to avoid individual identifications but maintain the statistical characteristics of the data \cite{mwiinga2023privacy}. Application of DP is expected to provide greater privacy protection against re-identification attacks of large data sets. DP protects the released output of a computation. It limits what an attacker can learn about any single person after the result is published. It does not protect the raw data during processing.\\ 
\noindent Homomorphic Encryption (HE) protects data while it is being computed on, and a server can process encrypted inputs without learning anything. It enables one to perform calculations directly with encrypted data and without the prior decryption. The technology is transforming safe data handling in sensitive areas such as medical care and finances. HE does not protect against privacy loss when the final output is released. It also does not support joint computation when several parties hold different data sources.
\\
The concept of Secure Multi-Party Computation (SMPC) enables collaborative calculations on encrypted data among various parties that mutually distrust each other, and does not reveal their respective inputs, and can be useful in inter-organizational data computation, such as financial audits. ZKPs are cryptographic techniques applied to confirm a statement is true without demonstrating the hidden information that causes the statement to be true. \cite{mwiinga2023privacy} \cite{aunon2024evaluation}.
\noindent More sophisticated PETs deal with environment of collaboration processing. Federated Learning (FL) is a type of distributed computing where the privacy of the data is conserved by training machine learning models using decentralized devices and transferring only the model parameters (weights) instead of the data \cite{aunon2024evaluation}. It is predicted that the use of FL will increase dramatically because it is one of the applications that can secure sensitive information of users as AI-based applications continue to be in high demand.
\subsection* {Frameworks for Responsible Data Sharing and Processing}
Effective deployment of Privacy Enhancing Technologies requires integrated technical frameworks to address specific privacy risks. Such frameworks offer adaptive protection mechanisms customized to various operational contexts. In Internet of Things (IoT), a dynamic model based on a fog computing infrastructure is one of them \cite{abi2025model}. In this structure, the framework employs a Smart Analyzer, which accepts user data and process them through a predefined knowledge database and Machine Learning (ML) algorithms to identify the need to protect privacy, data security, or a combination of the two, depending on the type of application or current situation.
The blockchain is a key element in ensuring reliability and integrity particularly in cases where both security and privacy are to be integrated without the involvement of a central party. Through its decentralized processing and inherent reliable hashing, blockchain highly guarantees reliability of information reported between two parties. This method can be combined with other methods including the Blind Approach where complete protection of privacy, security and integrity of data is ensured without placing any trust in any party. \cite{aunon2024evaluation}. 

\subsection* {Zero Trust, Identity Management, and Consent-Based Systems Upholding Ethics}
Technical compliance is not the only aspect to ethical data governance, but also respecting the autonomy and dignity of data owners. It also stops ethical misconducts like unsolicited digital profiling, behavioral targeting or covert identification of the users without their informed consent.\\

\noindent Security and privacy have a basic ethical and conceptual difference. Whereas information security has traditionally been perceived through the perspective of a trusting environment, where both sides share or store information with the confidence that the other party is trustworthy, privacy may be based on the reverse of this. The privacy-preserving systems should enable a user to use and enjoy the digital services without necessarily having to trust the service provider. Recognizing these ethical vulnerabilities, a new paradigm develops through the ZTA, which directly addresses the concerns of mistaken trust and excessive data gathering \cite{ahmadi2025autonomous}. ZTA is based on the philosophy of never trust, always verify. All users, devices, and applications, internal or external, must undergo an endless process of authentication, authorization, and validation, prior to receiving access. Zero trust is also ethically aligned with the principle of accountability by design because all actors are not trusted by default and data access is controlled by verifiably and consent-based policies.\\

\noindent In practical terms, Zero Trust principles are implemented through Identity and Access Management systems. These systems create authenticated digital identities and require low privilege access. When combined with consent-based methods, Identity and Access Management enables data sharing only with explicit and informed user consent \cite{feng2025identity}. Decentralized identity models, such as Self Sovereign identification, strengthen this approach by giving individuals cryptographic control over their identities and the ability to consent to transactions without centralized middlemen.\\

\noindent Advanced identity management, and consent-based converged architectures can give an intelligent and ethical system of balancing privacy and security. These types of models maintain credibility and functionality of the system without necessarily having to trust the service provider absolutely. They incorporate moral aspects of transparency, accountability, and respect of autonomy into the technological infrastructure itself, and make data protection not only a legal requirement but also a moral one and a functional requirement. Modern laws, such as the European law GDPR 2016, already obligate companies to verify the principle of privacy as well as the security of user data. Furthermore, these ethical and technical measures must be accompanied by communication techniques that make privacy and security controls visible and understandable to users. Even well-designed systems may lack legitimacy or acceptance if there is no transparency and user awareness. 

\section{Communication, Trust, and Public Perception}
\noindent The importance of proper communication and transparency is also essential to win the confidence and approval of the population concerning digital strategies and cybersecurity requirements. People also need more control, transparency, and security in regards to their personal data and internet communication \cite{kyriakoulis2025consentis}. Solutions like the CONSENTIS framework are aimed at providing the user with complete control over users' data, allowing one to make an informed consent, choose the data to share, and have a transparent view of the data in real-time. This will enable the data to be used in a way that will not compromise the control of the user, though will enable the stakeholders to easily find, demand, and access data in a cost-effective and legal manner. In addition, the major legal documents of the EU, including the GDPR, require data processors to address the rights of data subjects and specifically addresses the right to access (Article 15), which is directly linked to transparency. Kyriakoulis et. al. mentioned in their paper that  technologies such as blockchain and dynamic consent management systems is proposed to enhance security and accountability by providing tamper-proof traceability of transactions and maintaining a transparent system. It is also part of communication to provide active feedback to the user, an example of which is the CONSENTIS Discovery Mechanism that notifies the user about a request of his/her identity information and gives that user a chance to accept or decline it, and the Identity Wallet that informs the user and gives him/her monitoring abilities concerning the use of his/her data.\\

\noindent Public acceptance of cybersecurity regulations is greatly influenced by perceived threat and personal experience. After exposure to cyber incidents, many people are more willing to accept restrictive security measures that damage their privacy. Snider et. al. pointed that direct or indirect experience with cyberattacks tends to raise threat perception, which enhances public support for stricter cybersecurity regulation. This effect gets worse by early media coverage, especially when details about the culprit or the nature of the incident are few.\\

\noindent The results of the survey indicate the relationship between perception of threat and policy acceptance. A survey experiment that was a controlled randomized survey with an population of Israeli individuals who were exposed to simulated lethal or nonlethal cyberattacks established that exposure to cyberattacks (lethal and nonlethal) leads to increased support to embrace cybersecurity policies over a control group. In particular, individuals who have experienced lethal cyberattacks (LC) were more supportive of Cybersecurity Alert Policies (CAP) that forces the government to alert the residents on successful attacks on critical infrastructure or whether their computer had been hacked \cite{snider2021cyberattacks}. This implies that after terrorist-like attacks, citizens are more concerned with being educated about the imminent cyber attacks. On the other hand, nonlethal cyberattacks aimed at economic harm were likely to foster the backing of COP which promote direct intervention by the state to safeguard the citizens and enterprises. More importantly, the perceived threat was identified to moderate the association between personal experience of cyberattacks and the support of tougher cybersecurity policies on all the dimensions of policy (prevention, alert and oversight) that were tested. Across all circumstances, perceived threat proved a better predictor of policy support than previous personal experience. 
\\

\noindent These findings indicate that technical, ethical, and communicative efforts are interdependent. Public awareness and trust serve as catalysts in determining whether privacy and security measures are accepted and maintained. The next section combines these dimensions into a balanced framework for privacy and security.

\section{Synthesis - Toward a Balanced Framework for Privacy and Security}

Achieving a necessary balance between safeguarding individual privacy rights and ensuring robust collective security constitutes a fundamental challenge in the digital era. Equilibrium between individual rights and collective protection will not be obtained through the protection of technical and legal safeguards only unless backed by the public trust and ethical validity. The public trust, as observed in systems like the dynamic consent management, transparency systems like CONSENTIS or when creating the participatory policymaking systems, turn the compliance to shared responsibility rather than the obligation. When people understand and endorse the rationale behind cybersecurity and privacy measures, they become active participants in maintaining societal resilience rather than passive subjects of control. Such mutual trust helps policy-makers and technologists to create frameworks that do not only work efficiently on a technological level, but also on a social one and with moral foundations. Therefore, to achieve a reasonable privacy and security balance, it is necessary to balance both hard infrastructure-technical, legal and regulatory systems and soft infrastructure- communications, transparency and societal trust to be sure that the protection mechanisms are honoring the individual liberties and protecting the common good.\\

\noindent Finding a required balance between the rights of individuals to privacy and the needs to have strong collective security is one of the essential challenges of the digital age. The interaction between these two concepts is dynamic and is quite complex since in many cases studies tend to focus on addressing one subject at the expense of the other one, which is partly due to the fact that there is no clear understanding of the distinction between the two concepts. The scope of information security (IS) is all about ensuring the confidentiality, integrity and availability of information, which usually assumes that two parties involved in data transfer are trusting. On the other hand, data privacy is the right of the data owner to decide the exact usage of their data (who, when, where, why, and how) and it can mean that they need the services of a provider without necessarily trusting them altogether. In fact, it is often believed that a service provider is the most threatening party to the privacy of a user, since it is capable of accessing, processing, and abusing sensitive data. This lack of trust of the service provider becomes an issue because protecting privacy is arguably more challenging than protecting security.

\subsection {Comparative Analysis of Technical, Legal, and Ethical Measures}
After highlighting the need of balancing social and technical factors, this section discusses how technical, legal, and ethical systems interact to overcome the privacy-security dilemma.
The issue of privacy and security is a trade-off that needs to be combined on the technical, legal, and ethical levels.\\

\noindent \textbf{Technical Measures}: Technologically, researchers propose various approaches. PPTs are designed to protect sensitive data and allow its successful use  \cite{mwiinga2023privacy}. These include foundational methods like encryption (for secure transmission and confidentiality), anonymization (e.g., k-anonymity, l-diversity), and differential privacy (introducing noise to protect individual contributions). More sophisticated PPTs such as HE can be used to perform computations on encrypted inputs without decryption, and SMPC can be used to jointly analyze inputs without revealing a single one. These methods however come with trade-offs: encryption can add latency, as well as computational overhead, and anonymization/obfuscation methods can have an environmental impact on the quality or accuracy of the primary service that is being offered \cite{abi2025model}. Technical measures focus on resilience within a system by prioritizing strict security controls, high-tech analyses of threats and their prevention (Cyber Shield), and dynamic defensive strategies based on machine learning, artificial intelligence, and behavioral analytics \cite{safitra2023counterattacking}. Such techniques as blockchain can be used to improve security and trustworthiness (data integrity) due to an inherent hash and decentralized processing, but they may lead to the concerns about the privacy of participants.\\

\noindent \textbf{Legal and Ethical Measures}: Legal and regulatory frameworks need to be constantly adapted to the swift changes in technology and privacy issues in order to maintain the optimal balance in the needs of security and the rights of an individual. The laws of today like the European GDPR 2016 explicitly require businesses to confirm data security and privacy principles. At the ethical level, there is a discussion of the situation in which the usage of modern technologies could infringe the autonomy of the users or reproduce the biases in the decision-making processes of the algorithms \cite{mwiinga2023privacy}. Moreover, due to the international character of the data flow, it has become more difficult to align differences in privacy regulations in different jurisdictions and instead, the wholesome work should be done to create international standards. Balancing can only be achieved successfully through cooperation between technologists, policymakers, and ethicist.

\subsection* {Surveillance vs. Privacy; State vs. the individual interests}
The contradictory nature of the priorities of individual control over their personal data and the overall necessity to have security and utilize data is the root of the tension. Privacy refers to the right of the owner to the data to control the use, the whereabouts and tracing of the identity. Surveillance is also involved where service providers, which are considered the most dangerous to privacy, gather and analyze any available information about users in order to break their privacy \cite{abi2025model}. Whereas security is concerned with securing data against external attacks, privacy methods should also be used in securing the service provider. The possible clash between data use in better security (e.g. identification of abnormal behavior through analysis of images on surveillance cameras or sensor data, which is more inclined to protect security) and the protection of personal information is one of the key topics. Protecting privacy is arguably more difficult than protecting security due to this inherent lack of trust in the service provider.

\subsection* {Frameworks or Models that Propose Balanced Approaches}
\begin{itemize}
    \item Dynamic Balancing Model (IoT): This is a proposed model particularly in the case of the IoT application, in a bid to attain a dynamic equilibrium between privacy and security depending on the application or context. It is a method that works with a predefined knowledge database, a ML algorithm to identify data type and current conditions (e.g., recognize abnormal behavior), and an integration method, such as blockchain, should be employed (when needed) to provide strong protection (security, privacy, and data integrity) \cite{abi2025model}. This model aims at making sure that attention to one concept (privacy or security) will not infringe the other.
    \item Resilience Frameworks: The models of Cybersecurity resilience focus on organizational strengths to predict, withstand, heal, and adapt to cyber catastrophes. A strong framework incorporates a four stage life-cycle model (planning/preparation, absorption, recovery and adaptation). The strategy focuses on the implementation of security and resilience, which involve the aspects of technology, clear rules/processes, and human factors (security culture/awareness).
    \item Design Principles: It is advisable that businesses focus on Privacy by Design as it is best to incorporate privacy-sensitive technologies even in the product development process in order to foster trust. 
    \item Multistage 7Ps Model: This strategy combines the balanced scorecards and seven steps to boost resilience strategies: Patient, Persistent, Persevering, Proactive, Predictive, Preventive, and Preemptive \cite{safitra2023counterattacking}. This evolutionary approach helps organizations continuously adapt defenses based on real-time threats.
\end{itemize}

\subsection* {Identified Research Gaps and Future Directions}
Although a great amount of research has been done, there are still several crucial gaps specifically in the terms of reaching really balanced solutions and constant adjustment:
\begin{itemize}
    \item Comprehensive Protection Technology: No comprehensive protection technology has been developed yet that offers protection both in privacy and in security, that is, a single solution cannot be able to protect different types of applications and services simultaneously. The triple protection objective (Security, Privacy, and Reliability) is still in question.
    \item Incorporating Capabilities: There is a weakness in the overall examination of the connection between cybersecurity resilience and digitalization capabilities. The impacts of digitalization capabilities in resilience development are uncovered and require further detailed studies \cite{safitra2023counterattacking}.
    \item Development of Hybrid Techniques: Future studies should develop with complete and hybrid protection schemes. Certain hybrid methods currently under consideration are K-anonymity with blockchain, and the so-called Blind Approach (safeguarding privacy and security using multiple keys and a third party that does not know the identity, but cannot read the data) with blockchain \cite{abi2025model}.
    \item Adaptive Regulatory Frameworks: The policy makers should be at the forefront to have in place comprehensive and adaptive regulatory frameworks that finds a balance between innovation and the rights of the users.
    \item Technological Advances: The trends in the upcoming future are the increasing use of federated learning and development of better mechanisms of differential privacy to combat re-identification attacks. Ongoing R\&D is essential to enhance frameworks and address emerging cybersecurity threats.
\end{itemize}
\section{Key Takeaways}
\noindent Privacy and security are distinct yet interdependent aspects of digital protection. Privacy focuses more on the ability of the individual to control the personal data such as who can access it, how it is used and on what terms whereas security is concerned with protecting the data against external threats. The privacy protection is frequently more difficult due to the fact that the service providers may become dangerous themselves. Moral values such as trust, accountability and informed consent are essential to making sure that the privacy as well as security aspect is not vain, ineffective, and not socially unacceptable.\\

\noindent The rapid growth of digital technologies, especially IoT applications, has introduced complex cyber threats that traditional methods alone cannot address. The perception and awareness of the public about these threats are critical in determining the attitude of cybersecurity policies. Those who have been victims of cyberattacks or those whose behavior was reported in the media are more inclined to focus on the strictness of protection, which is why effective communication and openness are essential in order to create confidence in the digital ecosystem.\\

\noindent Privacy-Enhancing technologies (PET) such as Homomorphic Encryption, Differential Privacy, Federated Learning, Secure Multi-Party Computation, and Zero-Knowledge Proofs are technical frameworks that offer privacy-preserving and secure mechanisms of data analysis. These tools together with dynamic models such as fog-based IoT architecture, Smart Analyzers, blockchain, and Zero Trust framework can support adaptive and reliable management of privacy and security. This is due to the nature of trade-offs: when privacy is more heavily safeguarded, it can have an impact on the utility of data, its performance, or its computational performance, and thoughtful choices must be made when making a design or implementation decision. Technical frameworks, including Privacy-Enhancing Technologies (PETs) such as Homomorphic Encryption, Differential Privacy, Federated Learning, Secure Multi-Party Computation, and Zero-Knowledge Proofs, provide mechanisms for secure and privacy-preserving data analysis. These approaches and dynamic solutions as fog-based IoT frameworks, Smart Analysers, blockchain, and Zero Trust can support adaptive and reliable privacy and security management. Trade-offs are inherent, as stronger privacy protections can affect data utility, performance, or computational efficiency, requiring careful design and implementation decisions.\\ 

\noindent Technical solutions are supplemented by ethical and legal solutions. Consent-based identity management, Self-Sovereign Identity models, and Zero Trust architectures incorporate moral principles, like transparency, autonomy, accountability, into the system design. Such regulatory frameworks as GDPR and the EU Data Governance and Data Acts are legally binding norms that can be used to implement privacy and security, as well as enhance transparency and user empowerment. To reduce technological innovation and protect the rights of individuals across the borders, it is necessary to have adaptive, internationally aligned regulations. The social aspect is essential towards effective privacy and security. Trust, participatory governance, and clear communication empower individuals to actively engage in responsible data handling. Mechanisms like dynamic consent systems and the CONSENTIS framework enable users to control their data while maintaining transparency and accountability. Civil participation serves to both make the security measures technically and socially legitimate with regard to ensuring resilience in the digital ecosystem. \\ 

\noindent Lastly, a balanced framework can only be achieved by incorporating technical, ethical, legal and societal measures. The examples of models like dynamic IoT balancing frameworks, cybersecurity resilience strategies, Privacy by Design principles, and hybrid PET demonstrates how privacy, security, and reliability might be achieved simultaneously. There are still ongoing loopholes in the process of developing all-round solutions that would fulfill the various goals at the same time. A total of continuous investigation, innovation and administrative governance are necessary to develop trustworthy, resilient and ethically based digital frameworks that safeguard individual freedoms whilst not compromising collective security. \\